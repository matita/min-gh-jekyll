---
title: "The Netflix Tech Blog: Extracting image metadata at scale"
description: "null"
link: "http://techblog.netflix.com/2016/03/extracting-image-metadata-at-scale.html"
saved: "2016-03-22 14:18:00"
---

<div dir="ltr">
<br></div>
<div dir="ltr">
<span>We have a collection of nearly two million images that play very prominent roles in helping members pick what to watch. This blog describes how we use computer vision algorithms to address the challenges of focal point, text placement and image clustering at a large scale.</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>Focal point</span></div>
<div dir="ltr">
<span>All images have a region that is the most interesting (e.g. a character’s face, sharpest region, etc.) part of the image. In order to effectively render an image on a variety of canvases like a phone screen or TV, it is often required to display only the interesting region of the image and dynamically crop the rest of an image depending on the available real-estate and desired user experience. The goal of the focal point algorithm is to use a series of signals to identify the most interesting region of an image, then use that information to dynamically display it.</span></div>
<div dir="ltr">
<span><img alt="70177057_StoryArt_1536x864.jpg" height="167" src="https://lh3.googleusercontent.com/WA3MCMv7rS21s9_JFx6nWow3zAiu5LiD12luClSwoWWdUrJPNmSYkeBoVjMue1mHwpyHHFO_DPviuHgozjlhMa5MYrZ9g2jmvx7QqQKf503oODeThPhyAMG3AGhSM2K9CcDcW8ku" width="295"></span><span><img alt="80004288_StoryArt_1536x864 (2).jpg" height="166" src="https://lh4.googleusercontent.com/pL-7KC5GAiFd-yLgAdNaPKUZ3YhURNOIeuyY_7ESwoYmO4PlM1OsOgZZe1oJ1VuwqaIfFS7-W5r79Dgejqr-5DxZHC49GZaCQcTyA1DZEYxUGtitGW0jKu0j6MzTrP4nH1DlWxYx" width="295"></span></div>
<div dir="ltr">
<span>[Examples of face and full-body features to determine the focal point of the image]</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>We first try to identify all the people and their body positioning using </span><a href="http://dl.acm.org/citation.cfm?id=1127416"><span>Haar-cascade</span></a><span> like features. We also built haar based features to also identify if it is close-up, upper-body or a full-body shot of the person(s). With this information, we were able to build an algorithm that auto-selects what is considered the "best' or "most interesting" person and then focuses in on that specific location.</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>However, not all images have humans in them. So, to identify interesting regions in those cases, we created a different signal - edges. We heuristically identify the focus of an image based on first applying gaussian blur and then calculating edges for a given image. </span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>Here is one example of applying such a transformation:</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span><img alt="70300800_StoryArt_1536x864.jpg" height="148" src="https://lh3.googleusercontent.com/0lYEvNKN9pztfQ0fleB9Q09RE2_Bbc6MV8WpbvAmeg3Ux4uWDtLwQGKuRSk7mBWVyqNCpxjicjhuwxImGqcwQTF5bgIvnoRrchjuX57qCakRHP6GQ74hmoShW6g2l0kMhECkfaAr" width="256"></span><span>/</span><span><img height="148" src="https://lh3.googleusercontent.com/ZXWZdz1Cb3U86yVVlqTWI5OSP1tVhrwGYhlAKZ5FKFjxqdfQETi1MJ2UspjTpLgdCwnH-UTME47MlXRmxCu2mL0U70GGieA-YE9Y0i-JhlxNiQ09Z_RcU4L_jutt5YXHpdvAtiFc" width="248"></span></div>
<div dir="ltr">
<span><br></span></div>
<div dir="ltr">
<span>///Remove noise by blurring with a Gaussian filter</span></div>
<div dir="ltr">
<span>GaussianBlur( src, src, </span><span>Size</span><span>(</span><span>n</span><span>,</span><span>n </span><span>), </span><span>0</span><span>, </span><span>0</span><span>, </span><span>BORDER_DEFAULT </span><span>);</span></div>
<div dir="ltr">
<span>/// Convert the image to grayscale</span></div>
<div dir="ltr">
<span>cvtColor( src, src_gray, </span><span>CV_BGR2GRAY </span><span>);</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>/// Apply Laplace function</span></div>
<div dir="ltr">
<span>Laplacian( src_gray, dst, ddepth, kernel_size, scale, delta, </span><span>BORDER_CONSTANT </span><span>);</span></div>
<div dir="ltr">
<span>convertScaleAbs( dst, abs_dst );</span></div>
<b><br></b>
<div dir="ltr">
<span>Below are a few examples of dynamically cropped images based on focal point for different canvases:</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span><img alt="face.gif" height="428" src="https://lh3.googleusercontent.com/iIsB2viF4n9TjJWUB1RYZb1Qp43IR7JKGynmPIVn2-rZhL8wPlC5IWPy1VJrRHGFvAosbgnnG4At65aeHzeZygoitxSf8QNUXgHXHBCDnxqjalpkgHiP0ann00SAvQAoSQdZAslY" width="571"></span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>Text Placement</span></div>
<div dir="ltr">
<span>Another interesting challenge is determining what would be the best place to put text on an image. Examples of this are the ‘New Episode’ Badge and placement of subtitles in a video frame. </span></div>
<b><br></b>
<br>
<div dir="ltr">
<span><img alt="0.png" height="169" src="https://lh3.googleusercontent.com/Ubni8onAyb_0ZZkLWv1iYfcmvZMQt5_Xq9WAaoVHH2QPVhzkqMCjmXSsvx_I9ClR7bX5_pOXN-vWLp8AgQWxBbm5QfqXCNdjl6Rd8JeW2KXzg03LTEMN-SMYnNRH8j9bOcejyA_R" width="278"></span></div>
<div dir="ltr">
<span>[Example of “New Episode” badge hiding the title of the show]</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>In both cases, we’d like to avoid placing new text on top of existing text on these images.</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>Using a text detection algorithm allows us to automatically detect and correct such cases. However, text detection algorithms have many false positives. We apply several transformations like watershed and thresholding before applying text detection. With such transformations, we can get fairly accurate probability of text in a region of interest for image in large corpus of images.</span></div>
<div class="separator">
</div>
<div class="separator">
</div>
<div class="separator">
</div>
<div class="separator">
</div>
<br>
<b><br></b>
<br>
<div dir="ltr">
<span></span></div>
<div class="separator">
<a href="https://4.bp.blogspot.com/-ZCsM_YwvSIQ/VvBLNZkyDiI/AAAAAAAAA5A/FqfPqDjE9oMr6b9I0g7ri7AgCTgI-BACQ/s1600/Extracting%2Bimage%2Bmetadata%2Bat%2Bscale.jpg" imageanchor="1"><img border="0" height="288" src="https://4.bp.blogspot.com/-ZCsM_YwvSIQ/VvBLNZkyDiI/AAAAAAAAA5A/FqfPqDjE9oMr6b9I0g7ri7AgCTgI-BACQ/s640/Extracting%2Bimage%2Bmetadata%2Bat%2Bscale.jpg" width="640"></a></div>
<b><br></b>
<div dir="ltr">
<span><img alt="1e5b4580-bc6e-11e4-92d9-6306f841069d" height="247" src="https://lh3.googleusercontent.com/lh1rqov7OGQPZU5UejJfnZcWDp29Q7HIDmJ8HQ_JdkK8qMnmYquOJSi4S1GghVbYFiMljcxZwLRNOF-nVSfydg6nvTypJ1NnyVTAAzP9dAq7eJnbDsrSFS2SKyMGuv0B6vd5W2Av" width="175"></span><span><img alt="2.jpg" height="246" src="https://lh3.googleusercontent.com/U0BjLbLsHGXVCNAqI05xEHKdPFax06V34V1vmncwaspAiVZAKwfP1_z92sEdV_mIm1gShfhknwI1gKvFx_cDW-5nEsHsWtXC2Tg2fjr0SOkP902JNrMOkjVc82-6Hb0ax4z0CSnQ" width="177"></span><span><img alt="1.jpg" height="243" src="https://lh4.googleusercontent.com/UNjGdfHrDUhi7zAF_GEM1UBv50dlYWEHEQLzkRIXe3R7qIZjPIkSgnVOeDQvOKL4uVqmDRAn5FxxGr3GGja1UmO5Kvz_T2-NYwYF0J5rtynvdu3xWbPeIXUAVO2FHyt9Qg1im4RA" width="174"></span></div>
<div dir="ltr">
<span>[Results of text detection on some of the transformations of the same image]</span></div>
<b><br></b>
<div dir="ltr">
<span>Image Clustering</span></div>
<div dir="ltr">
<span>Images play an </span><a href="http://variety.com/2016/digital/news/netflix-ab-tests-image-optimization-trick-1201674325/"><span>important role</span></a><span> in a member’s decision to watch a particular video. We constantly test various flavors of artwork for different titles to decide which one performs the best. In order to learn which image is more effective globally, we would like to see how an image performs in a given region. To get an overall global view of how well a particular set of visually similar images performed globally, it is required to group them together based on their visual similarity.</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>We have several derivatives of the same image to display for different users. Although visually similar, not all of these images come from the same source. These images have varying degrees of image cropping, resizing, color correction and title treatment to serve a global audience. </span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>As a global company that is constantly testing and experimenting with imagery, we have a collection of millions of images that we are continuously shifting and evolving. Manually grouping these images and maintaining those images can be expensive and time consuming, so we wanted to create a process that was smarter and more efficient.</span></div>
<b><br></b>
<br>
<div dir="ltr">
<table><colgroup><col width="312"><col width="268"></colgroup><tbody>
<tr><td><div dir="ltr">
<span><img height="167" src="https://lh3.googleusercontent.com/wsJAUD0Lbb5HWdQPGxBPGpq2FNdK70RovCwe4PEr6KvJqcCesDMPXSoOGDYd0d_ySuChhe-q9GFSWf1zvmLQGOkk-9gpCNG0li3e_wV9PTXDDt__gUMCw1280yl4JolgyMKymWA9" width="297"></span></div>
</td><td><div dir="ltr">
<span><img height="167" src="https://lh4.googleusercontent.com/Y1YRXxWQZeSTqrT1C5glC8Iw_XsCQ3STfT_WTr1mC4X0_b2pUSClPzvIXqRH6GEZq9B4Y5h3HGuxcLVQ2xLwUhZDou5Kpvo3YqC0qHxe3vvgZL6cEofTjh1MQb7iQCumWnpGUDR2" width="240"></span></div>
</td></tr>
</tbody></table>
</div>
<div dir="ltr">
<span>[An example of two images with slight color correction, cropping and localized title treatment]</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>These images are often transformed and color corrected so a traditional color histogram based comparison does not always work for such automated grouping. Therefore, we came up with an algorithm that uses the following combination of parameters to determine a similarity index - measurement of visual similarity among group of images.</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>We calculate similarity index based on following 4 parameters:</span></div>
<ol>
<li dir="ltr"><div dir="ltr">
<span>Histogram based distance</span></div>
</li>
<li dir="ltr"><div dir="ltr">
<span>Structural similarity between two images </span></div>
</li>
<li dir="ltr"><div dir="ltr">
<span>Feature matching between two images </span></div>
</li>
<li dir="ltr"><div dir="ltr">
<span>Earth mover’s distance algorithm to measure overall color similarity</span></div>
</li>
</ol>
<b><br></b>
<br>
<div dir="ltr">
<span>Using all 4 methods, we can get a numerical value of similarity between two images in a relatively fast comparison. </span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>Below is example of images grouped based on a similarity index that is invariant to color correction, title treatment, cropping and other transformations:</span></div>
<div dir="ltr">
<span><img height="328" src="https://lh5.googleusercontent.com/iXWvMhj8Kn3NGrUBHPluNjPIC0QyrIopsIJAl5gvRi-1xqSETP9RAt2vK3t4BXLzu2X9oFtp2iNb4X0DyrjgZK245ZFH3H8-RMYjQG8Hr55V1KPk3-1Jfs5dlhRIB5LUuBgofMTa" width="624"></span></div>
<div dir="ltr">
<span>[Final result with similarity index values for group of images]</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>Images play a crucial role in first impression of a large collection of videos, and we are just scratching the surface on what we can learn from media and we have many more ambitious and interesting problems to tackle in the road ahead.</span></div>
<b><br></b>
<br>
<div dir="ltr">
<span>If you are excited and passionate about solving big problems, we are hiring. </span><a href="https://www.linkedin.com/in/apurvakansara"><span>Contact us</span></a></div>
<br>
<div dir="ltr">
<span>By </span><a href="https://www.linkedin.com/in/apurvakansara"><span>Apurva Kansara</span></a></div>
<div><div align="center">

<div><fb:comments href="http://techblog.netflix.com/2016/03/extracting-image-metadata-at-scale.html" title="Extracting image metadata at scale" width="450" xid="7447695948494141793" fb-xfbml-state="rendered" class="fb_iframe_widget"><span><iframe id="f10798e6fe76ba8" name="f15ebc2ce5310e" scrolling="no" title="Facebook Social Plugin" class="fb_ltr" src="https://www.facebook.com/plugins/comments.php?api_key=181875188571207&amp;channel_url=http%3A%2F%2Fstaticxx.facebook.com%2Fconnect%2Fxd_arbiter.php%3Fversion%3D42%23cb%3Dffe46ced33da74%26domain%3Dtechblog.netflix.com%26origin%3Dhttp%253A%252F%252Ftechblog.netflix.com%252Ff3ed274b02ccc2c%26relation%3Dparent.parent&amp;href=http%3A%2F%2Ftechblog.netflix.com%2F2016%2F03%2Fextracting-image-metadata-at-scale.html&amp;locale=en_US&amp;numposts=10&amp;sdk=joey&amp;width=450"></iframe></span></fb:comments></div>
</div></div>
<div></div>
